{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition\n",
    "**Linear regression** is a **supervised learining** algorithm used when target / dependent variable  **continues** real number. It establishes relationship between dependent variable $y$ and one or more independent variable $x$ using best fit line.   It work on the principle of ordinary least square $(OLS)$ / Mean square errror $(MSE)$. In statistics ols is method to estimated unkown parameter of linear regression function, it's goal is to minimize sum of square difference between observed dependent variable in the given data set and those predicted by linear regression fuction.\n",
    "\n",
    "## Hypothesis representation\n",
    "\n",
    "We will use $\\mathbf{x_i}$ to denote the independent variable and $\\mathbf{y_i}$ to denote dependent variable. A pair of $\\mathbf{(x_i,y_i)}$ is called training example. The subscripe $\\mathbf{i}$ in the notation is simply index into the training set. We have $\\mathbf{m}$ training example then $\\mathbf{i = 1,2,3,...m}$.\n",
    "\n",
    "The goal of supervised learning is to learn a *hypothesis function $\\mathbf{h}$*, for a given training set that can used to estimate $\\mathbf{y}$ based on $\\mathbf{x}$. So hypothesis fuction represented as \n",
    ">\n",
    ">$$\\mathbf{ h_\\theta(x_{i}) = \\theta_0 + \\theta_1x_i }$$   \n",
    "\n",
    "$\\mathbf{\\theta_0,\\theta_1}$ are parameter of hypothesis.This is equation for **Simple / Univariate Linear regression**. \n",
    "\n",
    "For **Multiple Linear regression** more than one independent variable exit then we will use $\\mathbf{x_{ij}}$ to denote indepedent variable and $\\mathbf{y_{i}}$ to denote dependent variable. We have $\\mathbf{n}$ independent variable then $\\mathbf{j=1,2,3 ..... n}$. The hypothesis function represented as\n",
    ">\n",
    ">$$\\mathbf{h_\\theta(x_{i}) = \\theta_0 + \\theta_1x_{i1} + \\theta_2 x_{i2} + ..... \\theta_j x_{ij} ...... \\theta_n  x_{mn} }$$\n",
    "\n",
    "$\\mathbf{\\theta_0,\\theta_1,....\\theta_j....\\theta_n }$ are parameter of hypothesis,\n",
    "$\\mathbf{m}$ Number of training exaples,\n",
    "$\\mathbf{n}$ Number of independent variable,\n",
    "$\\mathbf{x_{ij}}$ is $\\mathbf{i^{th}}$ training exaple of $\\mathbf{j^{th}}$ feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three different approaches to find the optimized values for the model parameters.**\n",
    "\n",
    "- Linear Regression with the Normal Equation\n",
    "- Linear Regression with Gradient Descent\n",
    "- Linear Regression with the Scikit-learn LinearRegression estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    " \n",
    "# Create data set.\n",
    "X, y = make_regression(\n",
    "    n_samples=n_samples, \n",
    "    n_features=1, \n",
    "    n_informative=1, \n",
    "    noise = 10, \n",
    "    random_state=10)\n",
    " \n",
    "# Convert  target variable array from 1d to 2d.\n",
    "y = y.reshape(n_samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 1), (500, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Normal equation.\n",
    "\n",
    "Usually finding the best model parameters is performed by running some kind of optimization algorithm (e.g. gradient descent) to minimize a cost function. However, it is possible to obtain values (weights) of these parameters by solving an algebraic equation called the normal equation as well.\n",
    "\n",
    ">$\\mathbf{\\theta = (X^T X)^{-1} X^Ty}$\n",
    "\n",
    "[Read more](https://towardsdatascience.com/performing-linear-regression-using-the-normal-equation-6372ed3c57)\n",
    "\n",
    "if you think you need to refresh your [linear algebra skills](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_regression_normal_equation(X, y):\n",
    "    ones = np.ones((X.shape[0], 1))\n",
    "    X = np.append(ones, X, axis=1)\n",
    "    W = np.dot(np.linalg.pinv(np.dot(X.T, X)), np.dot(X.T, y))\n",
    "    return W\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    W = linear_regression_normal_equation(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46338273],\n",
       "       [63.13879112]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with gradient decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is an iterative optimization algorithm to find the minimum of a function. Here that function is our Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "A cost function measures how much error in the model is in terms of ability to estimate the relationship between $x$ and $y$. \n",
    "We can measure the accuracy of our hypothesis function by using a cost function. This takes an average difference of observed dependent variable in the given the dataset and those predicted by the hypothesis function.\n",
    " \n",
    ">$$\\mathbf{J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m}(\\hat{y}_i - y_i)^2}$$\n",
    ">$$\\mathbf{J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m}(h_\\theta(x_i) - y_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, total_iterations=1000, print_cost=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.total_iterations = total_iterations\n",
    "        self.print_cost = print_cost\n",
    "\n",
    "    def y_hat(self, X, w):\n",
    "        return np.dot(w.T, X)\n",
    "\n",
    "    def cost(self, yhat, y):\n",
    "        C = 1 / self.m * np.sum(np.power(yhat - y, 2))\n",
    "\n",
    "        return C\n",
    "\n",
    "    def gradient_descent(self, w, X, y, yhat):\n",
    "        dCdW = 2 / self.m * np.dot(X, (yhat - y).T)\n",
    "        w = w - self.learning_rate * dCdW\n",
    "\n",
    "        return w\n",
    "    \n",
    "    def main(self, X, y):\n",
    "        # Add x1 = 1\n",
    "        ones = np.ones((1, X.shape[1]))\n",
    "        X = np.append(ones, X, axis=0)\n",
    "\n",
    "        self.m = X.shape[1]\n",
    "        self.n = X.shape[0]\n",
    "\n",
    "        w = np.zeros((self.n, 1))\n",
    "        costs = []\n",
    "        \n",
    "        for it in range(1, self.total_iterations + 1):\n",
    "            yhat = self.y_hat(X, w)\n",
    "            cost = self.cost(yhat, y)\n",
    "            # append to list\n",
    "            costs.append(cost)\n",
    "            \n",
    "            if it % 50 == 0 and self.print_cost:\n",
    "                print(f\"Cost at iteration {it} is {cost}\")\n",
    "\n",
    "            w = self.gradient_descent(w, X, y, yhat)\n",
    "\n",
    "        return w, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = 50\n",
    "regression = LinearRegression(total_iterations=total_iterations, print_cost=False)\n",
    "\n",
    "w, costs = regression.main(X.T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46338273],\n",
       "       [63.13879112]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = np.linspace(0, total_iterations, num=total_iterations)\n",
    "\n",
    "plt.plot(iterations, costs)\n",
    "plt.xlabel('Iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Create a linear regression model based the positioning of the data and Intercept, and predict a Best Fit:\n",
    "model = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.46338273]), array([[63.13879112]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important terms in Linear regression-**\n",
    "\n",
    "- **Best Fit** – the straight line in a plot that minimizes the deviation between related scattered data points.\n",
    "- **Coefficient** – also known as a parameter, is the factor a variable is multiplied by. In linear regression, a coefficient represents changes in a Response Variable (see below).\n",
    "- **Coefficient of Determination** – the correlation coefficient denoted as 𝑅². Used to describe the precision or degree of fit in a regression. \n",
    "- **Correlation** – the relationship between two variables in terms of quantifiable strength and degree, often referred to as the ‘degree of correlation’.  Values range between -1.0 and 1.0. \n",
    "- **Dependent Feature** – a variable denoted as y in the slope equation y=ax+b. Also known as an Output, or a Response. \n",
    "- **Estimated Regression Line** – the straight line that best fits a set of scattered data points.\n",
    "- **Independent Feature** – a variable denoted as x in the slope equation y=ax+b. Also known as an Input, or a predictor. \n",
    "- **Intercept** – the location where the Slope intercepts the Y-axis denoted b in the slope equation y=ax+b. \n",
    "- **Mean** – an average of a set of numbers, but in linear regression, Mean is modeled by a linear function.\n",
    "- **Ordinary Least Squares Regression (OLS)** – more commonly known as Linear Regression. \n",
    "- **Residual** – vertical distance between a data point and the line of regression (see Residual in Figure 1 below).\n",
    "- **Regression** – estimate of predictive change in a variable in relation to changes in other variables (see Predicted Response in Figure 1 below).\n",
    "- **Regression Model** – the ideal formula for approximating a regression.\n",
    "- **Response Variables** – includes both the Predicted Response (the value predicted by the regression) and the Actual Response, which is the actual value of the data point (see Figure 1 below).\n",
    "- **Slope** – the steepness of a line of regression. Slope and Intercept can be used to define the linear relationship between two variables: y=ax+b.\n",
    "- **Simple Linear Regression** – a linear regression that has a single independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
